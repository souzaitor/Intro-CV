{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection in a video using SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "class region_selector:\n",
    "    '''Class for letting the user select a region in the image'''\n",
    "    \n",
    "    def __init__(self, img):\n",
    "\n",
    "        self.img = img\n",
    "        self.img2draw = img\n",
    "        self.drawing = False\n",
    "        self.initial_x = -1\n",
    "        self.initial_y = -1\n",
    "        self.end_selection = False\n",
    "\n",
    "        cv2.namedWindow('image')\n",
    "        cv2.setMouseCallback('image', self.draw_rectangle)\n",
    "\n",
    "        while not self.end_selection:\n",
    "            cv2.imshow('image', self.img2draw)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def draw_rectangle(self, event, x, y, flags, param):\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drawing = True\n",
    "            self.initial_x = x\n",
    "            self.initial_y = y\n",
    "\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if self.drawing == True:\n",
    "                ix = self.initial_x\n",
    "                iy = self.initial_y\n",
    "                self.img2draw = self.img.copy()\n",
    "                cv2.rectangle(self.img2draw,(ix,iy),(x,y),(0,255,0),2)\n",
    "\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            self.drawing = False\n",
    "            ix = self.initial_x\n",
    "            iy = self.initial_y\n",
    "            self.img2draw = self.img.copy()\n",
    "            cv2.rectangle(self.img2draw,(ix,iy),(x,y),(0,255,0),2)\n",
    "\n",
    "            upper_left_x = ix if ix<x else x\n",
    "            upper_left_y = iy if iy < y else y\n",
    "            w = np.abs(ix - x)\n",
    "            h = np.abs(iy - y)\n",
    "            self.track_window = (upper_left_x, upper_left_y, w, h)\n",
    "            self.end_selection = True\n",
    "\n",
    "def get_matched_image(img_scene, kp_obj, des_object, img_obj, sift):\n",
    "    ''' Match keypoints from the object to keypoints detected in img_scene'''\n",
    "    \n",
    "    t = time()\n",
    "    kp_scene, des_scene = sift.detectAndCompute(img_scene,None)\n",
    "    t = time()-t\n",
    "    #print(\"detect: {}\".format(t))\n",
    "\n",
    "    # crossCheck=True returns only matching points p1 and p2 where p2 is the \n",
    "    # closest point to p1 and p1 is also the closest to p2\n",
    "    bf = cv2.BFMatcher(crossCheck=True)\n",
    "\n",
    "    t = time()\n",
    "    matches = bf.knnMatch(des_object, des_scene, k=1)\n",
    "    t = time()-t\n",
    "    #print(\"match1: {}\".format(t))\n",
    "\n",
    "    t = time()\n",
    "    good = []\n",
    "    for m in matches:\n",
    "        if len(m)!=0:\n",
    "            good.append(m[0])\n",
    "    t = time()-t\n",
    "    #print(\"match2: {}\".format(t))\t \n",
    "\n",
    "    # Find good matches using Lowe's ratio test\n",
    "    # good = []\n",
    "    # for m1, m2 in matches:\n",
    "    #     if m1.distance/m2.distance < 0.7:\n",
    "    #         good.append(m1)\n",
    "\n",
    "    if len(good)<=10:\n",
    "        img_matches_RANSAC = cv2.drawMatches(img_obj, kp_obj, img_scene, kp_scene, good, None)\n",
    "        #img_matches_RANSAC - img_scene\n",
    "    else:\n",
    "        obj_pts = np.zeros([len(good), 2], dtype=np.float32)\n",
    "        scene_pts = np.zeros([len(good), 2], dtype=np.float32)\n",
    "        for i, m in enumerate(good):\n",
    "            obj_pts[i] = kp_obj[m.queryIdx].pt\n",
    "            scene_pts[i] = kp_scene[m.trainIdx].pt\n",
    "\n",
    "        # T is the transformation matrix, mask is a boolean array indicating inlier points\n",
    "        T, mask = cv2.findHomography(obj_pts, scene_pts, cv2.RANSAC, ransacReprojThreshold=3.0) \n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "        # Find transformation of rectangle delimiting object\n",
    "        h, w = img_obj.shape\n",
    "        obj_bounds = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0] ]).reshape(-1,1,2)\n",
    "        obj_bounds_in_scene = cv2.perspectiveTransform(obj_bounds, T)\n",
    "\n",
    "        img_scene_obj = cv2.polylines(img_scene.copy(), [np.int32(obj_bounds_in_scene)], True, 255, 3, cv2.LINE_AA)\n",
    "        img_matches_RANSAC = img_scene_obj\n",
    "        #img_matches_RANSAC = cv2.drawMatches(img_obj, kp_obj, img_scene_obj, kp_scene, good, \n",
    "            #      None, matchesMask=matchesMask, matchColor=(255,0,0), singlePointColor=(0,0,255))\n",
    "\n",
    "\n",
    "    return img_matches_RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture first frame for object selection\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Let the user select the object\n",
    "rs = region_selector(frame)        \n",
    "upper_left_x, upper_left_y, w, h = rs.track_window\n",
    "\n",
    "img_obj = frame[upper_left_y:upper_left_y+h, upper_left_x:upper_left_x+w]\n",
    "img_obj_g = cv2.cvtColor(img_obj, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# SIFT detector object for both images\n",
    "sift = cv2.xfeatures2d.SIFT_create(nfeatures=0, nOctaveLayers=3, contrastThreshold=0.02, \n",
    "                                   edgeThreshold=10, sigma=1.6)\n",
    "kp_obj, des_obj = sift.detectAndCompute(img_obj_g, None)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_g = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    # Resize image for better performance\n",
    "    frame_g_res = cv2.resize(frame_g, (640, 360))\n",
    "    t = time()\n",
    "    img_matches_RANSAC = get_matched_image(frame_g_res, \n",
    "                                           kp_obj, des_obj, \n",
    "                                           img_obj_g, sift)  \n",
    "    t = time()-t\n",
    "    #print(\"function: {}\".format(t))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', img_matches_RANSAC)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
